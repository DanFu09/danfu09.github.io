11-13-19: Rekall: A Programming Model for Rapidly Defining Events of Interest in Video
Intel Autonomous Driving Community of Practice Event

(INTERNAL, DAWN) 09-10-19: Why Learn What You Already Know? Rekall: A Compositional Approach to Video Analysis
DAWN Retreat

(INTERNAL, SVL) 06-10-19: Rekall: Modeling Concepts in Video with Compositions of Spatiotemporal Labels
Stanford Vision Lab

(INTERNAL, G-cafe) 04-18-19: Modeling Concepts in Video with Compositions of Spatiotemporal Labels
Stanford Graphics Group

(INTERNAL, Stanford MLSys Seminar) 04-21-22: Improving Transfer and Robustness of Supervised Contrastive Learning

06-07-22: Improving Transfer and Robustness of Supervised Contrastive Learning
KitWare Vision Research Group

06-07-22: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
Google N2Formal Team

06-08-22: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
MosaicML

06-24-22: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
Meta PyTorch Performance Team

07-14-22: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
MLOps World: Machine Learning in Production

02-14-23: Hungry Hungry Hippos - H3
AI Pub Deep Papers Podcast, Episode 2

02-21-23: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
CS 217: Hardware Accelerators for Machine Learning

03-02-23: Hungry Hungry Hippos: Towards Language Modeling with state Space Models
IBM

03-17-23: FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness
Google

05-12-23: Perspectives in Generative AI Panel
Pear VC

05-22-23: Language Modeling with State Space Models
TWIML AI Podcast

09-07-23: Hungry Hungry Hippos and Monarch Mixer
Neural Notes Podcast

11-07-23: Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture
SystemX Conference

11-11-23: Efficient Sub-Quadratic Architectures for Machine Learning
Bangkok AI Hack 2023